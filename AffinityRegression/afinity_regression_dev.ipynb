{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # affinity regression:\n",
    "\n",
    "# # RWA^T = Y\n",
    "# # R:  low-level embeddings\n",
    "# # W: weight matrix to learn\n",
    "# # A: RNA/protein sequences to match\n",
    "# # Y: known matches\n",
    "# (samples, embedding dim)     (hidden1, hidden2)   (rna_samples, dim_rna_samples)^T      = (# RNAs, expression over dim_rna_samples)\n",
    "# (100, 1000)                  (1000, 45)            (45, 20394)                          = (100, 20394)\n",
    "    \n",
    "    \n",
    "# emb_dim: hidden embedding\n",
    "# match_dim: # rna_samples\n",
    "# out_dim: d\n",
    "\n",
    "# samples = batch_size\n",
    "# embedding_dim = learned embedding dim (emb_dim)\n",
    "# hidden1 = embedding_dim\n",
    "# hidden2 = dimension of rna samples (rna_dim)\n",
    "# rna_samples = # of RNA samples we're looking at\n",
    "\n",
    "# output dimensions:\n",
    "#     # samples we're looking at\n",
    "#     # number of RNA samples we're looking at \n",
    "\n",
    "class AfinityRegression(nn.Module):\n",
    "    def __init__(self, emb_dim, rna_dim):\n",
    "        super(AfinityRegression, self).__init__()\n",
    "        # want to learn weights after applying to embedding layer (First do RW , then RW A^T)\n",
    "        self.lin1 = nn.Linear(emb_dim, rna_dim)\n",
    "    \n",
    "    def forward(self, batch_size, embs, rna_samples):\n",
    "        self.batch_size = batch_size\n",
    "        x = self.lin1(embs)\n",
    "        print(x.size())\n",
    "        print(rna_samples.size())\n",
    "        x = torch.matmul(x, rna_samples)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([777, 2555])\n",
      "torch.Size([2555, 30])\n",
      "torch.Size([777, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([777, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# samples = batch_size                              777\n",
    "# embedding_dim = learned embedding dim (emb_dim)   10\n",
    "# hidden1 = embedding_dim                           10\n",
    "# hidden2 = dimension of rna samples (rna_dim)      2555\n",
    "# rna_samples = # of RNA samples we're looking at   30\n",
    "\n",
    "test_model = AfinityRegression(emb_dim=10, rna_dim=2555)\n",
    "optimizer = SGD(test_model.parameters(), lr = 0.001)\n",
    "\n",
    "\n",
    "learned_embs = Variable(torch.randn((777,10)))\n",
    "poss_matches = Variable(torch.randn((2555, 30)))\n",
    "known_matches = Variable(torch.randn((777,30)))\n",
    "\n",
    "outs = test_model.forward(3, learned_embs, poss_matches)\n",
    "new_mat = known_matches - outs\n",
    "losses = torch.bmm(new_mat.view(new_mat.size()[0], 1, new_mat.size()[1]),\n",
    "                   new_mat.view(new_mat.size()[0], new_mat.size()[1], 1)\n",
    "                  )\n",
    "print(losses.size())\n",
    "torch.sqrt(losses).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([777, 30])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
